-----------------------------------------------------------------------
| CHAPTER 3 - MANAGING TERRAFORM STATE                                |
-----------------------------------------------------------------------

- Terraform State

    - Every time you run Terraform, it records information about what infrastructure it created in a 'tfstate' file.
        if you run Terraform in the /foo/bar folder, a file /foo/bar/terraform.tfstate is created.
        

    - This file contains a custom JSON format that maps resources in your configuration files to representations of
        those resources in the real world.  

        [Terraform]
        resource "aws_instance" "example" {
          ami = "ami-0fb653ca2d3203ac1"
          instance_type = "t2.micro"
        }

        [Snippet of terraform.tfstate]
        {
            "version": 4,
            "terraform_version": "1.2.3",
            "serial": 1,
            "lineage": "86545604-7463-4aa5-e9e8-a2a221de98d2",
            "outputs": {},
            "resources": [
            {
            "mode": "managed",
            "type": "aws_instance",
            "name": "example",
            "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
            "instances": [
            {
            "schema_version": 1,
            "attributes": {
            "ami": "ami-0fb653ca2d3203ac1",
            "availability_zone": "us-east-2b",
            "id": "i-0bc4bbe5b84387543",
            "instance_state": "running",
            "instance_type": "t2.micro",
            "(...)": "(truncated)",
            ...
        }


    - Every time you run Terraform, it fetches the latest version of the resources defined and compare to the
        configuration to determine what changes are needed.


    - Running these commands from your laptop is fine for a personal project, but in production you'll run into 3
        problems:

        1. Shared Storage for state files = Every team member needs access to state files to update infrastructure
        2. Locking state files = Concurrent updates can lead to conflicts
        3. Isolating state files = How can separate environments use the same tfstate file?



- Shared Storage for State Files

    - The best way to maange shared state is to use Terraform's built in support for remote backend.  A 'backend'
        defines how Terraform loads and stores state.  The 'local backend' is the default backend.  A 'remote backend'
        allows you to store state in a remote, shared store.


    - If you're using AWS, S3 is usually used as a remote backend.
        - Inexpensive managed service that is highly durable and available
        - Supports encryption at rest (AES-256) and in transit (TLS)
        - Supports locking via DynamoDB
        - Supports versioning


    - To enable remote state storage with Amazon S3, first define an S3 bucket where you will store your
        Terraform state (in a new main.tf file in a new folder):

        provider "aws" {
          region = "us-east-2"
        }

        resource "aws_s3_bucket" "terraform_state" {
          bucket = "terraform-up-and-running-state"

          # Prevent accidental deletion of this S3 bucket
          # Any attempt to delete this resource causes TF to exit with an error
          lifecycle {
            prevent_destroy = true
          }
        }


    - Now, we'll add several extra layers of protection to this bucket.  First, we'll add versioning:

        # Enable versioning so you can see the full revision history of your state files
        resource "aws_s3_bucket_versioning" "enabled" {
          bucket = aws_s3_bucket.terraform_state.id
          versioning_configuration {
            status = "Enabled"
          }
        }


    - Next, we'll turn on server-side encryption on by default for all data written to this S3 bucket, so that
        state files will always be encrypted on disk:

        # Enable server-side encryption by default
        resource "aws_s3_bucket_server_side_encryption_configuration" "default" {
          bucket = aws_s3_bucket.terraform_state.id
          rule {
            apply_server_side_encryption_by_default {
              sse_algorithm = "AES256"
            }
          }
        }


    - Finally, we'll block all public access to the S3 bucket.  S3 buckets are private by default, but they since
        they are used to serve static assets it is easy to make them public.  It adds an extra layer of
        protection to ensure this bucket can't accidentally be made public.

        # Explicitly block all public access to the S3 bucket
        resource "aws_s3_bucket_public_access_block" "public_access" {
          bucket = aws_s3_bucket.terraform_state.id
          block_public_acls = true
          block_public_policy = true
          ignore_public_acls = true
          restrict_public_buckets = true
        }


    - Next, we need to create a DynamoDB table that can be used for locking.  To use DynamoDB for locking with
        Terraform, you must create a table with a primary key called 'LockID'.

        resource "aws_dynamodb_table" "terraform_locks" {
          name = "terraform-up-and-running-locks"
          billing_mode = "PAY_PER_REQUEST"
          hash_key = "LockID"
          attribute {
            name = "LockID"
            type = "S"
          }
        }


    - Now, we can run 'terraform init' to download the provider code, and 'terraform apply' to deploy.  Our
        S3 bucket and Dynamo table will be created, but our state will still be stored locally.


    - To configure TF to store your state in your S3 bucket:

        terraform {
          backend "s3" {
            # Replace this with your bucket name!
            bucket = "terraform-up-and-running-state"
            key = "global/s3/terraform.tfstate"
            region = "us-east-2"

            # Replace this with your DynamoDB table name!
            dynamodb_table = "terraform-up-and-running-locks"
            encrypt = true
          }
        }

      Then when you run 'terraform init', TF will automatically detect you already have a state file locally,
        and ask if you want to copy it to the new backend.


    - When you run 'terraform apply', you'll see the ARN (Amazon Resource Name) of the S3 bucket, and the name
        of your new DynamoDB table.



- 