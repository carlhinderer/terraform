-----------------------------------------------------------------------
| CHAPTER 2 - GETTING STARTED WITH TERRAFORM                          |
-----------------------------------------------------------------------

- Setting Up AWS Account

    - We'll log into our root user account.  The only thing we should use the root user account for is 
        to create other user accounts with more limited permissions, then switch to these user accounts
        immediately.


    - To create a more limited user account:

        - IAM Service
            > Add User
                > Name: terraform-user
                > Access Key - Programmatic Access


    - By default, new IAM users have no permissions.  To give the user permissions, you need to assoicate
        one or more IAM policies with the user's account.  An 'IAM Policy' is a JSON document that defines
        what the user is or isn't allowed to do.  You can create your own IAM policies or use the predefined
        policies built into your account ('Managed Policies').

      To run examples in this book, the easiest way is to add the 'AdministratorAccess' Managed Policy to
        your IAM user.


    - Create the user, then copy the 'Access Key Id' and 'Secret Access Key', since they will never be
        shown again.  Consider saving them in LastPass or some other password manager.


    - All of the AWS examples in this book use the 'Default VPC' in your account.  

        - A 'VPC' (Virtual Private Cloud) is an isolated area of your AWS account that has it's own virtual
            network and IP address space.  

        - Just about every AWS resource deploys into a VPC.  If you don't explicitly specify a VPC, the
            resource will be deployed into the default VPC.



- Installing Terraform

    - The easiest way to install Terraform is to use your OS's package manager.

        # Homebrew on MacOS
        $ brew tap hashicorp/tap
        $ brew install hashicorp/tap/terraform


    - To install on Ubuntu using APT

        # Install required dependencies
        $ apt-get install wget curl unzip software-properties-common gnupg2 -y

        # Add the Hashicorp repository to apt
        $ apt-add-repository "deb [arch=$(dpkg --print-architecture)] https://apt.releases.hashicorp.com $(lsb_release -cs) main"

        # Update the repository
        $ apt-get update -y

        # Install Terraform
        $ apt-get install terraform -y

        # Verify installation
        $ terraform -v


    - To install the auto-complete Terraform extension:

        $ terraform -install-autocomplete
        $ source ~/.bashrc


    - In order for Terraform to make changes to your AWS account, you'll need to set the creds for the IAM
        account you created earlier:

        $ export AWS_ACCESS_KEY_ID=(your access key id)
        $ export AWS_SECRET_ACCESS_KEY=(your secret access key)

      Alternatively, Terraform supports the same authentication mechanisms as all AWS CLI and SDK tools.
        It can use credentials in $HOME/.aws/credentials, which are automatically generated if you run
        'aws configure', or IAM roles, which you can add to almost any resource in AWS.



- Deploying a Single Server

    - Terraform code is written in HCL, in files with the extension '.tf'.  Terraform can create 
        infrastructure across a variety of platforms (which is calls 'providers').


    - The first step is typically to configure the provider you want to use.  Create an empty folder and
        put a file called 'main.tf' into it:

        # main.tf
        ---------------------
        provider "aws" {
          region = "us-east-2"
        }


    - AWS has datacenters all over the world, grouped into regions (ie us-east-2 or eu-west-1).  Within each 
        region, there are multiple isolated datacenters known as Availability Zones or AZ's (ie us-east-2a
        or us-east-2b).


    - For each type of provider, there are many different types of 'resources' you can create, such as
        servers, databases, and load balancers.  The general syntax for creating a resource is:

        resource "<PROVIDER>_<TYPE>" "<NAME>" {
          [CONFIG ...]
        }

        PROVIDER      # Name of provider
        TYPE          # Resource to create in the provider
        NAME          # Identifier that can be used throughout Terraform code
        CONFIG        # Arguments specific to the resource


    - Here is an example of deploying a single EC2 instance, which we'll add to 'main.tf'.

        # main.tf
        ---------------------
        resource "aws_instance" "example" {
          ami           = "ami-0fb653ca2d3203ac1"
          instance_type = "t2.micro"
        }


    - An AMI (Amazon Machine Instance) is the server template used to run an EC2 instance.  There are free
        and paid AMIs in the AWS Marketplace.  You can also create your own AMIs using tools like Packer.
        Note that the AMI IDs are different in every AWS region, so you need to look up the corresponding
        IDs if you use a different region.


    - Next, we'll run the 'terraform init' command, which scans your code, figures out which providers
        you are using, and downloads the code for them into a '.terraform' folder.  Terraform will also
        record which versions of the provider code it downloaded into a '.terraform.lock.hcl' file.  The
        'init' command is idempotent, so it can be run multiple times.

        $ cd code
        $ terraform init


    - Now, we can run the 'plan' command to see what will be done before making any actual changes.

        $ terraform plan

        # Plan lines
        +     Will be created
        -     Will be deleted
        ~     Will be modified in place


    - To actually create the instance, run the 'apply' command.

        $ terraform apply


    - We now have our EC2 instance running, but it doesn't have a name.  To add one, we'll add a tag to
        the resource, then run 'apply' to add the name.

        # main.tf
        --------------
        resource "aws_instance" "example" {
          ami = "ami-0fb653ca2d3203ac1"
          instance_type = "t2.micro"

          tags = {
            Name = "terraform-example"
          }
        }


    - Terraform keeps track of all the resources it already created for this set of config files, so it
        knows your EC2 instance already exists and modifies it in place.



- Deploying a Single Web Server

    - For the simplest possible web server, we'll use a tool called 'busybox' that is installed by default
        on Ubuntu.  We'll wrap the busybox command with a 'nohup' and '&' so that the web server runs
        permanently in the background whereas the bash script itself can exit.

        #!/bin/bash
        echo "Hello, World" > index.html
        nohup busybox httpd -f -p 8080 &


    - Note that we use port 8080 instead of 80, because listening on any port less than 1024 requires
        root user privileges.  This is a security risk, since any attacker who manages to compromise your
        server would get root privileges, too.  Therefore, it is a best practice to listen on 
        higher-numbered ports.


    - Normally, a tool like Packer would be used to create a custom AMI that has a web server installed on
        it.  For this simple web server, we'll just add our shell script to our EC2 intance's User Data,
        which will be executed by the EC2 instance during it's first boot.

      We'll use the Terraform 'user_data_replace_on_true' setting so that when the 'user_data' paremter is
        changed, the original instance will be terminated and a new one will be created.

        resource "aws_instance" "example" {
          ami           = "ami-0fb653ca2d3203ac1"
          instance_type = "t2.micro"

          user_data = <<-EOF
                      #!/bin/bash
                      echo "Hello, World" > index.html
                      nohup busybox httpd -f -p 8080 &
                      EOF

          user_data_replace_on_change = true

          tags = {
            Name = "terraform-example"
          }
        }


    - By default, AWS does not allow any incoming or outgoing traffic from an EC2 instance.  To allow the
        EC2 instance to receive traffic on port 8080, we need to create a security group:

        resource "aws_security_group" "instance" {
          name = "terraform-example-instance"

          ingress {
            from_port = 8080
            to_port = 8080
            protocol = "tcp"
            cidr_blocks = ["0.0.0.0/0"]
          }
        }


    - This security group allows incoming TCP requests on port 8080 from the CIDR block 0.0.0.0/0.  CIDR
        blocks are a concise way to specify IP address ranges.  For example, a CIDR block of 10.0.0.0/24
        represents all IP addresses between 10.0.0.0 and 10.0.0.255.  The CIDR block 0.0.0.0/0 is an IP
        address range that includes all possible IP addresses.


    - Now, we also need to tell our EC2 instance to use the new security group by passing the ID of the
        security group.  To do that, we'll need to use a Terraform expression.

        - An 'expression' in Terraform is anything that returns a value.  So far, we have used only 
            literals.

        - One particularly useful type of expression is a reference, which takes the form:
            <PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE> (ie aws_security_group.instance.id)


    - We'll add this attribute to our EC2 instance resource:

        vpc_security_group_ids = [aws_security_group.instance.id]


    - When you add a reference from one resource to another, you create an 'implicit dependency'.
        Terraform parses these dependencies, builds a dependency graph from them, and uses it to 
        determine which order to create resources in.  To see the dependency graph:

        $ terraform graph

      The output is in a graph description language called DOT, so you can use it to create an image of
        the graph using a tool like Graphviz.


    - Now, we can run 'apply' to create the new security group and re-create the EC2 instance.  Note that
        while the web server is being replaced, users will experience downtime.  We'll learn how to do a
        zero-downtime deployment later.


    - If we click our new instance in the console, we can get it's public IP address from the description
        panel.  We can use a web browser or a tool like curl to make a request to this IP address.

        $ curl http://<EC2_INSTANCE_PUBLIC_IP>:8080



- Network Security

    - To keep the examples in this book simple, all deploy into the Default VPC into the default
        subnets of that VPC.

    - A VPC is partitioned into one or more subnets, each of which has it's own IP addresses.

    - The subnets in the Default VPC are all public subnets, which means they get IP addresses that
        are accessible from the public internet.  This is why we can test our EC2 instances from our home 
        computer.

    - Running a server in a public subnet like this is a security risk in the real world.  Hackers are
        constantly scanning IP addresses at random for any weakness.  If your servers are exposed publicly,
        leaving a single port unprotected or running out-of-date code can allow someone to break in.

    - Therefore, for all production servers, you should deploy all of your servers and data stores in
        private subnets, which have IP addresses that can be accessed only from within the VPC and not
        from the public internet.

    - The only servers you should run in public subnets are a small number of reverse proxies and load
        balancers that you lock down as much as possible.